{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nlp\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Access a webpage using Python (use package urllib)\n",
    "2. Remove HTML tags using regular expression\n",
    "3. Identify the following patterns:\n",
    "○ Email id: id@domain\n",
    "○ IP address\n",
    "○ Phone number\n",
    "○ Website address\n",
    "○ Abbreviations (all capitals)\n",
    "○ Proper nouns (name of company/person/places)\n",
    "○ Numbers\n",
    "○ Dates\n",
    "4. Prepare the set of unique words\n",
    "5. Now create a new vocabulary after:\n",
    "○ Removing stopwords\n",
    "○ Treating words irrespective of cases (upper/lower)\n",
    "○ Applying stemming\n",
    "6. Compare the set of words in steps 4 and 5. How much reduction have\n",
    "you achieved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "Here i used beautiful soup to get the page contents that has the information. We scrap it using soup and retrive only required info from the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "page = requests.get(\"https://github.com/Siddharth1698/Natural-Language-Processing/blob/main/LAB/LAB%203/nlp_data.txt\")\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 200 response suggest that it is succesful and we have got the page that was requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"blob-code blob-code-inner js-file-line\" id=\"LC1\">Jane Austine</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC2\">DR. in UX Design for Websites designing</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC3\">9342178394</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC4\">145 Baker St., Kozhikode KL. 673001</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC5\">69.89.31.226</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC6\">www.janaustine.com</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC7\">janeaustine@gmail.com</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC8\">10-01-1991</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC9\">\n",
       " </td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC10\">Mary James</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC11\">PHD. in Django developers for web development</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC12\">9042178494</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC13\">111 Bounce St., Kannur KL. 673008</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC14\">66.89.41.216</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC15\">www.maryjames.com</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC16\">maryjames@gmail.com</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC17\">16-07-1990</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC18\">\n",
       " </td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC19\">Bruno Fernandes</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC20\">SP. in Football for footballing assosiation. </td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC21\">9100179394</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC22\">101 Choclate St., Thrissur KL. 680005</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC23\">60.69.51.221</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC24\">www.brunofernandes.com</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC25\">brunofernandes@gmail.com</td>,\n",
       " <td class=\"blob-code blob-code-inner js-file-line\" id=\"LC26\">01-09-1989</td>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"blob-code blob-code-inner js-file-line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the find_all property to specify a class and retrive all tags that belong to that particular tag. Here we can see that we have retrived all the users information which are available in the td tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"blob-code blob-code-inner js-file-line\" id=\"LC1\">Jane Austine</td>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('td', id = 'LC1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def REhtmlTag(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a function REhtmlTag that takes the tagged html line and uses regular expressions to remove all the html tags and generate the main text available on webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in range(1,27):\n",
    "    x = soup.find('td', id = f'LC{i}')\n",
    "    y = REhtmlTag(str(x))\n",
    "    li.append(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through all the td's and generating the main texts and adding it to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jane Austine',\n",
       " 'DR. in UX Design for Websites designing',\n",
       " '9342178394',\n",
       " '145 Baker St., Kozhikode KL. 673001',\n",
       " '69.89.31.226',\n",
       " 'www.janaustine.com',\n",
       " 'janeaustine@gmail.com',\n",
       " '10-01-1991',\n",
       " '\\n',\n",
       " 'Mary James',\n",
       " 'PHD. in Django developers for web development',\n",
       " '9042178494',\n",
       " '111 Bounce St., Kannur KL. 673008',\n",
       " '66.89.41.216',\n",
       " 'www.maryjames.com',\n",
       " 'maryjames@gmail.com',\n",
       " '16-07-1990',\n",
       " '\\n',\n",
       " 'Bruno Fernandes',\n",
       " 'SP. in Football for footballing assosiation. ',\n",
       " '9100179394',\n",
       " '101 Choclate St., Thrissur KL. 680005',\n",
       " '60.69.51.221',\n",
       " 'www.brunofernandes.com',\n",
       " 'brunofernandes@gmail.com',\n",
       " '01-09-1989']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jane Austine DR. in UX Design for Websites designing 9342178394 145 Baker St., Kozhikode KL. 673001 69.89.31.226 www.janaustine.com janeaustine@gmail.com 10-01-1991 \\n Mary James PHD. in Django developers for web development 9042178494 111 Bounce St., Kannur KL. 673008 66.89.41.216 www.maryjames.com maryjames@gmail.com 16-07-1990 \\n Bruno Fernandes SP. in Football for footballing assosiation.  9100179394 101 Choclate St., Thrissur KL. 680005 60.69.51.221 www.brunofernandes.com brunofernandes@gmail.com 01-09-1989'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join([str(elem) for elem in li]) \n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "Identifying all the patterns from the scrapped text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['janeaustine@gmail.com', 'maryjames@gmail.com', 'brunofernandes@gmail.com']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = re.findall('\\S+@\\S+', text) \n",
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-01-1991', '16-07-1990', '01-09-1989']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = re.findall('\\d+-\\d+-\\d+',text)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9342178394', '9042178494', '9100179394']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone = re.findall('\\d{10}', text) \n",
    "phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DR.', 'KL.', 'PHD.', 'KL.', 'SP.', 'KL.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbr = re.findall('(\\S+[A-Z]\\.)+', text) \n",
    "abbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['janaustine.com', 'maryjames.com', 'brunofernandes.com']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website = re.findall('www.([\\w\\-\\.]+)', text) \n",
    "website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['69.89.31.226', '66.89.41.216', '60.69.51.221']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip=re.findall(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",text)\n",
    "ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jane',\n",
       " 'Austine',\n",
       " 'DR',\n",
       " 'in',\n",
       " 'UX',\n",
       " 'Design',\n",
       " 'for',\n",
       " 'Websites',\n",
       " 'designing',\n",
       " 'Baker',\n",
       " 'St',\n",
       " 'Kozhikode',\n",
       " 'KL',\n",
       " 'www',\n",
       " 'janaustine',\n",
       " 'com',\n",
       " 'janeaustine',\n",
       " 'gmail',\n",
       " 'com',\n",
       " 'Mary',\n",
       " 'James',\n",
       " 'PHD',\n",
       " 'in',\n",
       " 'Django',\n",
       " 'developers',\n",
       " 'for',\n",
       " 'web',\n",
       " 'development',\n",
       " 'Bounce',\n",
       " 'St',\n",
       " 'Kannur',\n",
       " 'KL',\n",
       " 'www',\n",
       " 'maryjames',\n",
       " 'com',\n",
       " 'maryjames',\n",
       " 'gmail',\n",
       " 'com',\n",
       " 'Bruno',\n",
       " 'Fernandes',\n",
       " 'SP',\n",
       " 'in',\n",
       " 'Football',\n",
       " 'for',\n",
       " 'footballing',\n",
       " 'assosiation',\n",
       " 'Choclate',\n",
       " 'St',\n",
       " 'Thrissur',\n",
       " 'KL',\n",
       " 'www',\n",
       " 'brunofernandes',\n",
       " 'com',\n",
       " 'brunofernandes',\n",
       " 'gmail',\n",
       " 'com']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = re.findall('[A-Za-z]+',text)\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9342178394',\n",
       " '145',\n",
       " '673001',\n",
       " '69.89.31.226',\n",
       " '10-01-1991',\n",
       " '9042178494',\n",
       " '111',\n",
       " '673008',\n",
       " '66.89.41.216',\n",
       " '16-07-1990',\n",
       " '9100179394',\n",
       " '101',\n",
       " '680005',\n",
       " '60.69.51.221',\n",
       " '01-09-1989']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = re.findall('\\S+[0-9]', text) \n",
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "Preparing the set of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jane',\n",
       " 'Austine',\n",
       " 'DR',\n",
       " 'in',\n",
       " 'UX',\n",
       " 'Design',\n",
       " 'for',\n",
       " 'Websites',\n",
       " 'designing',\n",
       " 'Baker',\n",
       " 'St',\n",
       " 'Kozhikode',\n",
       " 'KL',\n",
       " 'www',\n",
       " 'janaustine',\n",
       " 'com',\n",
       " 'janeaustine',\n",
       " 'gmail',\n",
       " 'com',\n",
       " 'Mary',\n",
       " 'James',\n",
       " 'PHD',\n",
       " 'in',\n",
       " 'Django',\n",
       " 'developers',\n",
       " 'for',\n",
       " 'web',\n",
       " 'development',\n",
       " 'Bounce',\n",
       " 'St',\n",
       " 'Kannur',\n",
       " 'KL',\n",
       " 'www',\n",
       " 'maryjames',\n",
       " 'com',\n",
       " 'maryjames',\n",
       " 'gmail',\n",
       " 'com',\n",
       " 'Bruno',\n",
       " 'Fernandes',\n",
       " 'SP',\n",
       " 'in',\n",
       " 'Football',\n",
       " 'for',\n",
       " 'footballing',\n",
       " 'assosiation',\n",
       " 'Choclate',\n",
       " 'St',\n",
       " 'Thrissur',\n",
       " 'KL',\n",
       " 'www',\n",
       " 'brunofernandes',\n",
       " 'com',\n",
       " 'brunofernandes',\n",
       " 'gmail',\n",
       " 'com']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = re.findall('[^\\W\\d_]+', text)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have all the words available in the text. Next we generate an corpus with all the unique words in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Austine',\n",
       " 'Baker',\n",
       " 'Bounce',\n",
       " 'Bruno',\n",
       " 'Choclate',\n",
       " 'DR',\n",
       " 'Design',\n",
       " 'Django',\n",
       " 'Fernandes',\n",
       " 'Football',\n",
       " 'James',\n",
       " 'Jane',\n",
       " 'KL',\n",
       " 'Kannur',\n",
       " 'Kozhikode',\n",
       " 'Mary',\n",
       " 'PHD',\n",
       " 'SP',\n",
       " 'St',\n",
       " 'Thrissur',\n",
       " 'UX',\n",
       " 'Websites',\n",
       " 'assosiation',\n",
       " 'brunofernandes',\n",
       " 'com',\n",
       " 'designing',\n",
       " 'developers',\n",
       " 'development',\n",
       " 'footballing',\n",
       " 'for',\n",
       " 'gmail',\n",
       " 'in',\n",
       " 'janaustine',\n",
       " 'janeaustine',\n",
       " 'maryjames',\n",
       " 'web',\n",
       " 'www'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(words)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. \n",
    "We remove the stop words from the corpus we generated and perform stemming on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DR', 'janeaustine', 'SP', 'Baker', 'Austine', 'janaustine', 'com', 'gmail', 'Mary', 'PHD', 'brunofernandes', 'assosiation', 'Fernandes', 'Choclate', 'KL', 'developers', 'Websites', 'web', 'Jane', 'Kannur', 'UX', 'Football', 'Kozhikode', 'maryjames', 'Thrissur', 'St', 'www', 'footballing', 'Design', 'development', 'Bruno', 'Bounce', 'James', 'Django', 'designing']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))  \n",
    "  \n",
    "word_tokens = unique_words\n",
    "  \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
    "  \n",
    "filtered_sentence = []  \n",
    "  \n",
    "for w in word_tokens:  \n",
    "    if w not in stop_words:  \n",
    "        filtered_sentence.append(w)  \n",
    "  \n",
    "print(filtered_sentence)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the words that we finally have after removing the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_wl = []\n",
    "   \n",
    "ps = PorterStemmer() \n",
    "\n",
    "for w in filtered_sentence: \n",
    "    stem_wl.append(ps.stem(w))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DR',\n",
       " 'KL',\n",
       " 'SP',\n",
       " 'St',\n",
       " 'UX',\n",
       " 'assosi',\n",
       " 'austin',\n",
       " 'baker',\n",
       " 'bounc',\n",
       " 'bruno',\n",
       " 'brunofernand',\n",
       " 'choclat',\n",
       " 'com',\n",
       " 'design',\n",
       " 'develop',\n",
       " 'django',\n",
       " 'fernand',\n",
       " 'footbal',\n",
       " 'gmail',\n",
       " 'jame',\n",
       " 'janaustin',\n",
       " 'jane',\n",
       " 'janeaustin',\n",
       " 'kannur',\n",
       " 'kozhikod',\n",
       " 'mari',\n",
       " 'maryjam',\n",
       " 'phd',\n",
       " 'thrissur',\n",
       " 'web',\n",
       " 'websit',\n",
       " 'www'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words = set(stem_wl)\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the words after we perform stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. \n",
    "Comparing words generated after steps 5 and 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Austine',\n",
       " 'Baker',\n",
       " 'Bounce',\n",
       " 'Bruno',\n",
       " 'Choclate',\n",
       " 'DR',\n",
       " 'Design',\n",
       " 'Django',\n",
       " 'Fernandes',\n",
       " 'Football',\n",
       " 'James',\n",
       " 'Jane',\n",
       " 'KL',\n",
       " 'Kannur',\n",
       " 'Kozhikode',\n",
       " 'Mary',\n",
       " 'PHD',\n",
       " 'SP',\n",
       " 'St',\n",
       " 'Thrissur',\n",
       " 'UX',\n",
       " 'Websites',\n",
       " 'assosiation',\n",
       " 'brunofernandes',\n",
       " 'com',\n",
       " 'designing',\n",
       " 'developers',\n",
       " 'development',\n",
       " 'footballing',\n",
       " 'for',\n",
       " 'gmail',\n",
       " 'in',\n",
       " 'janaustine',\n",
       " 'janeaustine',\n",
       " 'maryjames',\n",
       " 'web',\n",
       " 'www'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DR',\n",
       " 'KL',\n",
       " 'SP',\n",
       " 'St',\n",
       " 'UX',\n",
       " 'assosi',\n",
       " 'austin',\n",
       " 'baker',\n",
       " 'bounc',\n",
       " 'bruno',\n",
       " 'brunofernand',\n",
       " 'choclat',\n",
       " 'com',\n",
       " 'design',\n",
       " 'develop',\n",
       " 'django',\n",
       " 'fernand',\n",
       " 'footbal',\n",
       " 'gmail',\n",
       " 'jame',\n",
       " 'janaustin',\n",
       " 'jane',\n",
       " 'janeaustin',\n",
       " 'kannur',\n",
       " 'kozhikod',\n",
       " 'mari',\n",
       " 'maryjam',\n",
       " 'phd',\n",
       " 'thrissur',\n",
       " 'web',\n",
       " 'websit',\n",
       " 'www'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR  :  DR\n",
      "janeaustine  :  janeaustin\n",
      "SP  :  SP\n",
      "Baker  :  baker\n",
      "Austine  :  austin\n",
      "janaustine  :  janaustin\n",
      "com  :  com\n",
      "gmail  :  gmail\n",
      "Mary  :  mari\n",
      "PHD  :  phd\n",
      "brunofernandes  :  brunofernand\n",
      "assosiation  :  assosi\n",
      "Fernandes  :  fernand\n",
      "Choclate  :  choclat\n",
      "KL  :  KL\n",
      "developers  :  develop\n",
      "Websites  :  websit\n",
      "web  :  web\n",
      "Jane  :  jane\n",
      "Kannur  :  kannur\n",
      "UX  :  UX\n",
      "Football  :  footbal\n",
      "Kozhikode  :  kozhikod\n",
      "maryjames  :  maryjam\n",
      "Thrissur  :  thrissur\n",
      "St  :  St\n",
      "www  :  www\n",
      "footballing  :  footbal\n",
      "Design  :  design\n",
      "development  :  develop\n",
      "Bruno  :  bruno\n",
      "Bounce  :  bounc\n",
      "James  :  jame\n",
      "Django  :  django\n",
      "designing  :  design\n"
     ]
    }
   ],
   "source": [
    "for w in filtered_sentence: \n",
    "    print(w, \" : \", ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There has been upto 5 words reduction after stemming in our corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
